---
title: "Solutions"
output: github_document
date: "2024-11-20"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(modelr)
library(knitr)
library(purrr)
```


```{R}
#PROBLEM 2
hom_data = read.csv("homicide-data.csv")|>
  janitor::clean_names()|>
  mutate(city_state = paste(city, state, sep = ", "))|>
  filter(city_state != c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO")) |>
  filter(city_state != "Tulsa, AL") |>
  filter(victim_race == c("Black", "White")) |>
  mutate(victim_age = as.integer(victim_age)) |>
  mutate(
    disposition = str_replace(disposition, "Closed by arrest", "Solved"), 
    disposition = str_replace(disposition, "Closed without arrest", "Unsolved"), 
    disposition = str_replace(disposition, "Open/No arrest", "Unsolved")
  )|>
  mutate(disposition_binary = ifelse(disposition == "Solved", 1, 0)) |>
  select(city_state, disposition_binary, victim_age, victim_sex, victim_race)

balt_data = hom_data |>
  filter(city_state == "Baltimore, MD") 

# Fit logistic regression model
glm_fit <- glm(disposition_binary ~ victim_age + victim_sex + victim_race, data = balt_data, family = binomial)

glm_fit |>
  broom::tidy() |>
  mutate(OR = exp(estimate), 
         CI_lower = confint(glm_fit)[,1], 
         CI_upper = confint(glm_fit)[,2]) |>
  select(term, log_OR = estimate, OR, CI_lower, CI_upper, p.value) |>
  knitr::kable(digits = 3)



```



```{R}
#PROBLEM 3

#cleaning
bwtdf = read.csv("birthweight.csv") |>
  mutate( frace = as.factor(frace),
          mrace = as.factor(mrace),
          babysex = as.factor(babysex)
  )|>
  drop_na()
model <- lm(bwt ~ babysex + fincome + wtgain + ppbmi, data = bwtdf)
tidy_fit <- model |>
  broom::tidy()
kable(tidy_fit, caption = "MLR stats")
# Adding predictions and residuals to the data
train_data <- bwtdf |>
  add_predictions(model) |>
  add_residuals(model)
# Plot
ggplot(train_data, aes(x = pred, y = resid)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE, color = "blue") +
  labs(title = "Residuals vs Fitted Values", x = "Fitted Values", y = "Residuals") +
  theme_minimal()
```
Modelling process- I decided to use the variables family income, baby's sex, mother's pre pregnancy BMI and weight gain during pregnancy. Baby's sex is a biological trait which influences weight (boys tend to weigh more). The others were related to the mother's weight and economic conditions. The table we made suggested that all these 4 variables have a statistically significant relationship (very small p values).

About the plot: Our plot indicates that our model is not the best- i.e. our choice of variables for predicting weight and the way we constructed the model could have been better. Ideally, we want the line to be flatter and closer to zero to signify a linear relationship. The line is only close to 0 in the middle. Some of our points are very far from 0 which is not what we want.

Q- Compare your model to two others:

One using length at birth and gestational age as predictors (main effects only)
One using head circumference, length, sex, and all interactions (including the three-way interaction) between these

Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate.

Making two more models and comparing as instructed:

```{R}
model2 = lm(bwt ~ blength + gaweeks, data = bwtdf)
model3 = lm(bwt ~ bhead + blength + babysex + 
              bhead * blength * babysex + blength * babysex + babysex * bhead
             + blength * bhead, data = bwtdf)
# Setting seed for reproducibility
set.seed(123)

# Creating Monte Carlo cross-validation folds
cv_folds <- crossv_mc(bwtdf, n = 100, test = 0.2) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

# Fitting models
cv_folds <- cv_folds |> 
  mutate(
    fit_model = map(train, ~ lm(formula(model), data = .)),
    fit_model2 = map(train, ~ lm(formula(model2), data = .)),
    fit_model3 = map(train, ~ lm(formula(model3), data = .))
  )

# Calculating RMSE for each model
cv_folds <- cv_folds |> 
  mutate(
    rmse_model = map2_dbl(fit_model, test, ~ rmse(model = .x, data = .y)),
    rmse_model2 = map2_dbl(fit_model2, test, ~ rmse(model = .x, data = .y)),
    rmse_model3 = map2_dbl(fit_model3, test, ~ rmse(model = .x, data = .y))
  )

# Reshaping and plotting the results
cv_folds |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    cols = everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin() +
  labs(
    x = "Model Name",
    y = "RMSE",
    title = "Cross-Validation Comparison"
  )


```

Our third model (using head circumference, length, sex, and all interactions (including the three-way interaction) demonstrates the lowest RMSE, indicating it provides the best fit among the models tested. The second model follows as the next best performer, while the initial model we started with exhibits the highest RMSE and thus the least effective.

We can make plots like we did for our original model to confirm: 

```{R} 
train_data_ <- bwtdf |>
  add_predictions(model2) |>
  add_residuals(model2)
# Plot
ggplot(train_data_, aes(x = pred, y = resid)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE, color = "lightblue") +
  labs(title = "Residuals vs Fitted Values", x = "Fitted Values", y = "Residuals") +
  theme_minimal()
train_data_new <- bwtdf |>
  add_predictions(model3) |>
  add_residuals(model3)
# Plot
ggplot(train_data_new, aes(x = pred, y = resid)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE, color = "cyan") +
  labs(title = "Residuals vs Fitted Values", x = "Fitted Values", y = "Residuals") +
  theme_minimal()
```

Plot for model2- Line is not flat and not close to 0 at lower and higher values. We observe that model3 is better from the plots.

Plot for model3 -We observer that apart from the start, the line is flat and close to 0 and the points aren't as scattered away from 0 as in our first plot. This signifies an improvement. However, there are still issues with this model (especially for lower values of the fitted variable).

